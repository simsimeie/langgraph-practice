{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:00:53.065299Z",
     "start_time": "2025-07-06T22:00:42.907267Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -qU pypdf langchain-community langchain-text-splitters",
   "id": "9687bd0b3e2aa3ae",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:27:36.970847Z",
     "start_time": "2025-07-06T22:27:35.357717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_file_path = './Brief_2023년12월호_F.pdf'\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ],
   "id": "d7ffa595365ecaed",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:27:45.901274Z",
     "start_time": "2025-07-06T22:27:45.895195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# OCR을 적용하지 않은 PyPDFLoader는 표 등의 형태를 읽을 수 없다.\n",
    "print(pages[10])"
   ],
   "id": "cf43f585408e595d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='SPRi AI Brief |  2023-12월호\n",
      "8\n",
      "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개n코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, 작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시n대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 구성과 계보도 추적 가능\n",
      "KEY Contents\n",
      "£데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상nAI 기업 코히어(Cohere)가 매사추세츠 공과⼤(MIT), 하버드⼤ 로스쿨, 카네기멜론⼤ 등 12개 기관과 함께 2023년 10월 25일 ‘데이터 출처 탐색기(Data Provenance Explorer)’ 플랫폼을 공개∙AI 모델 훈련에 사용되는 데이터셋의 불분명한 출처로 인해 데이터 투명성이 확보되지 않아 다양한 법적·윤리적 문제가 발생∙이에 연구진은 가장 널리 사용되는 2,000여 개의 미세조정 데이터셋을 감사 및 추적하여 데이터셋에 원본 데이터소스에 대한 태그, 재라이선스(Relicensing) 상태, 작성자, 기타 데이터 속성을 지정하고 이러한 정보에 접근할 수 있는 플랫폼을 출시∙대화형 플랫폼 형태의 데이터 출처 탐색기를 통해 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며, 주요 데이터셋의 구성과 데이터 계보도 추적 가능n연구진은 오픈소스 데이터셋에 대한 광범위한 감사를 통해 데이터 투명성에 영향을 미치는 주요 요인을 발견∙깃허브(GitHub), 페이퍼위드코드(Papers with Code)와 같은 크라우드소싱 플랫폼에서 수집한 데이터로 훈련된 오픈소스 LLM에서는 데이터 라이선스의 누락 비율이 72~83%에 달함 ∙또한 크라우드소싱 플랫폼이 할당한 라이선스는 데이터셋 원저작자의 의도보다 더 광범위한 사용을 허용한 경우가 상당수∙데이터 생태계 분석 결과, 부정확하거나 모호한 라이선스 문서화 등 데이터 출처 입증과 관련된 관행 전반에서 구조적 문제가 드러남n연구진은 데이터 출처 탐색기만으로는 해결이 어려운 법적 이슈도 존재한다며 일관된 법적 프레임워크의 필요성을 제기∙일례로 데이터를 수집한 지역, 모델 훈련 지역, 모델 배포 지역마다 규제가 다르면 어떤 법률을 적용해야 하는지 실무자의 판단이 어려울 수 있으며, 서로 다른 라이선스를 적용받는 개별 데이터셋을 하나로 통합해 사용하는 경우에도 각각의 라이선스 조건 준수에 어려움이 발생☞ 출처 : Cohere, Data Provenance Explorer Launches to Tackle Data Transparency Crisis, 2023.10.25.' metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 10, 'page_label': '11'}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:32:00.154177Z",
     "start_time": "2025-07-06T22:31:53.481678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# py-zerox는 LLM을 활용해 PDF 파일을 읽고 마크다운 형식으로 변환해준다.\n",
    "!pip install py-zerox"
   ],
   "id": "2de592a70f5eb9a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py-zerox\r\n",
      "  Downloading py_zerox-0.0.7-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting aiofiles>=23.0 (from py-zerox)\r\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: aiohttp>=3.9.5 in ./.venv/lib/python3.11/site-packages (from py-zerox) (3.12.13)\r\n",
      "Collecting pdf2image>=1.17.0 (from py-zerox)\r\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Collecting litellm>=1.44.15 (from py-zerox)\r\n",
      "  Downloading litellm-1.74.0-py3-none-any.whl.metadata (40 kB)\r\n",
      "Collecting aioshutil>=1.5 (from py-zerox)\r\n",
      "  Downloading aioshutil-1.5-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting PyPDF2>=3.0.1 (from py-zerox)\r\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.9.5->py-zerox) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.9.5->py-zerox) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.9.5->py-zerox) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.9.5->py-zerox) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.9.5->py-zerox) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.9.5->py-zerox) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.9.5->py-zerox) (1.20.1)\r\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.9.5->py-zerox) (3.10)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2 in ./.venv/lib/python3.11/site-packages (from aiosignal>=1.1.2->aiohttp>=3.9.5->py-zerox) (4.14.0)\r\n",
      "Collecting click (from litellm>=1.44.15->py-zerox)\r\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: httpx>=0.23.0 in ./.venv/lib/python3.11/site-packages (from litellm>=1.44.15->py-zerox) (0.28.1)\r\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm>=1.44.15->py-zerox)\r\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\r\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in ./.venv/lib/python3.11/site-packages (from litellm>=1.44.15->py-zerox) (3.1.6)\r\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in ./.venv/lib/python3.11/site-packages (from litellm>=1.44.15->py-zerox) (4.24.0)\r\n",
      "Requirement already satisfied: openai>=1.68.2 in ./.venv/lib/python3.11/site-packages (from litellm>=1.44.15->py-zerox) (1.93.0)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in ./.venv/lib/python3.11/site-packages (from litellm>=1.44.15->py-zerox) (2.11.7)\r\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in ./.venv/lib/python3.11/site-packages (from litellm>=1.44.15->py-zerox) (1.1.1)\r\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./.venv/lib/python3.11/site-packages (from litellm>=1.44.15->py-zerox) (0.9.0)\r\n",
      "Collecting tokenizers (from litellm>=1.44.15->py-zerox)\r\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.44.15->py-zerox) (3.0.2)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.15->py-zerox) (2025.4.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.15->py-zerox) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.15->py-zerox) (0.26.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.44.15->py-zerox) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.44.15->py-zerox) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.44.15->py-zerox) (0.4.1)\r\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm>=1.44.15->py-zerox) (4.9.0)\r\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm>=1.44.15->py-zerox) (2025.6.15)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm>=1.44.15->py-zerox) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.44.15->py-zerox) (0.16.0)\r\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm>=1.44.15->py-zerox)\r\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.68.2->litellm>=1.44.15->py-zerox) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.68.2->litellm>=1.44.15->py-zerox) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai>=1.68.2->litellm>=1.44.15->py-zerox) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai>=1.68.2->litellm>=1.44.15->py-zerox) (4.67.1)\r\n",
      "Collecting pillow (from pdf2image>=1.17.0->py-zerox)\r\n",
      "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm>=1.44.15->py-zerox) (2024.11.6)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm>=1.44.15->py-zerox) (2.32.4)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.44.15->py-zerox) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.44.15->py-zerox) (2.5.0)\r\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->litellm>=1.44.15->py-zerox)\r\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox)\r\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox)\r\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox) (6.0.2)\r\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.44.15->py-zerox)\r\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\r\n",
      "Downloading py_zerox-0.0.7-py3-none-any.whl (23 kB)\r\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\r\n",
      "Downloading aioshutil-1.5-py3-none-any.whl (4.7 kB)\r\n",
      "Downloading litellm-1.74.0-py3-none-any.whl (8.6 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.6/8.6 MB\u001B[0m \u001B[31m16.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\r\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\r\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\r\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\r\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\r\n",
      "Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.6/6.6 MB\u001B[0m \u001B[31m18.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m25.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\r\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m26.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\r\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Installing collected packages: zipp, PyPDF2, pillow, hf-xet, fsspec, filelock, click, aioshutil, aiofiles, pdf2image, importlib-metadata, huggingface-hub, tokenizers, litellm, py-zerox\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15/15\u001B[0m [py-zerox]7m━━━━━\u001B[0m \u001B[32m13/15\u001B[0m [litellm]]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed PyPDF2-3.0.1 aiofiles-24.1.0 aioshutil-1.5 click-8.2.1 filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.5 huggingface-hub-0.33.2 importlib-metadata-8.7.0 litellm-1.74.0 pdf2image-1.17.0 pillow-11.3.0 py-zerox-0.0.7 tokenizers-0.21.2 zipp-3.23.0\r\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:32:12.912908Z",
     "start_time": "2025-07-06T22:32:12.907922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "ed33655afb47cb00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:32:16.086762Z",
     "start_time": "2025-07-06T22:32:15.200354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 노트북 환경에서 py-zerox를 실행하기 위해 설치\n",
    "!pip install -q nest_asyncio"
   ],
   "id": "7e84278c4f27e44e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:32:23.369745Z",
     "start_time": "2025-07-06T22:32:23.363416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "id": "ce55b3f74988a1da",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:34:24.917077Z",
     "start_time": "2025-07-06T22:34:01.242169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyzerox import zerox\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "### 모델 설정 (Vision 모델만 사용) 참고: https://docs.litellm.ai/docs/providers ###\n",
    "\n",
    "## 일부 모델에 필요할 수 있는 추가 모델 kwargs의 자리 표시자\n",
    "kwargs = {}\n",
    "\n",
    "## Vision 모델에 사용할 시스템 프롬프트\n",
    "custom_system_prompt = None\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "# 메인 비동기 진입점을 정의합니다\n",
    "async def main():\n",
    "    ## 일부 페이지 또는 전체 페이지를 처리\n",
    "    select_pages = None ## 전체는 None, 특정 페이지는 int 또는 list(int) 페이지 번호 (1부터 시작)\n",
    "\n",
    "    output_dir = \"./documents\" ## 통합된 마크다운 파일을 저장할 디렉토리\n",
    "    result = await zerox(file_path=pdf_file_path, model=model, output_dir=output_dir,\n",
    "                        custom_system_prompt=custom_system_prompt, select_pages=select_pages, **kwargs)\n",
    "    return result\n",
    "\n",
    "\n",
    "# 메인 함수를 실행합니다:\n",
    "result = asyncio.run(main())\n",
    "\n",
    "# 마크다운 결과를 출력합니다\n",
    "print(result)"
   ],
   "id": "438ab452dd0845a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to process image Error:\n",
      "    Error in Completion Response. Error: litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o-mini in organization org-BUqMelELa1Zym4EJ6FENpbIW on tokens per min (TPM): Limit 200000, Used 200000, Requested 807. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "    Please check the status of your model provider API status.\n",
      "    \n",
      "ERROR:root:Failed to process image Error:\n",
      "    Error in Completion Response. Error: litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o-mini in organization org-BUqMelELa1Zym4EJ6FENpbIW on tokens per min (TPM): Limit 200000, Used 200000, Requested 807. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "    Please check the status of your model provider API status.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to process image Error:\n",
      "    Error in Completion Response. Error: litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o-mini in organization org-BUqMelELa1Zym4EJ6FENpbIW on tokens per min (TPM): Limit 200000, Used 200000, Requested 807. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "    Please check the status of your model provider API status.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to process image Error:\n",
      "    Error in Completion Response. Error: litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o-mini in organization org-BUqMelELa1Zym4EJ6FENpbIW on tokens per min (TPM): Limit 200000, Used 200000, Requested 807. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "    Please check the status of your model provider API status.\n",
      "    \n",
      "ERROR:root:Failed to process image Error:\n",
      "    Error in Completion Response. Error: litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o-mini in organization org-BUqMelELa1Zym4EJ6FENpbIW on tokens per min (TPM): Limit 200000, Used 200000, Requested 807. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "    Please check the status of your model provider API status.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to process image Error:\n",
      "    Error in Completion Response. Error: litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o-mini in organization org-BUqMelELa1Zym4EJ6FENpbIW on tokens per min (TPM): Limit 200000, Used 200000, Requested 807. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "    Please check the status of your model provider API status.\n",
      "    \n",
      "ERROR:root:Failed to process image Error:\n",
      "    Error in Completion Response. Error: litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o-mini in organization org-BUqMelELa1Zym4EJ6FENpbIW on tokens per min (TPM): Limit 200000, Used 200000, Requested 807. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "    Please check the status of your model provider API status.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to process image Error:\n",
      "    Error in Completion Response. Error: litellm.RateLimitError: RateLimitError: OpenAIException - Rate limit reached for gpt-4o-mini in organization org-BUqMelELa1Zym4EJ6FENpbIW on tokens per min (TPM): Limit 200000, Used 200000, Requested 807. Please try again in 242ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "    Please check the status of your model provider API status.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001B[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "ZeroxOutput(completion_time=21943.296, file_name='brief_2023년12월호_f', input_tokens=553140, output_tokens=9155, pages=[Page(content='# SPRi AI Brief\\n\\n## 인공지능 산업의 최신 동향\\n\\n### 2023년 12월호\\n\\n![SPRi](https://example.com/path/to/image.png)  \\n**소프트웨어 정책연구소**  \\n', content_length=119, page=1), Page(content=\"# CONTENTS\\n\\n## I. 인공지능 산업 동향 브리프\\n\\n1. 정책/법제\\n   - 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정령 발포 .......................................................... 1\\n   - G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령 채택 .................................................... 2\\n   - 영국 AI 안전정 상장회의에 참가한 28개국, AI 위험에 공동 대응 선언 ................................................ 3\\n   - 미국 법원, 예술가들이 생성한 AI 기업에 제기한 저작권 소송 기각 .................................................... 4\\n   - 미국 연방거래위원회, 저작권침해 소비자 보호와 경쟁 촉진의 AI 의결서 제출 .................................. 5\\n   - EU allem 3차 협상, 기초모델 규제 관련 견해자료 난형 ............................................................. 6\\n\\n2. 기업/산업\\n   - 미국 프론티어 모델 포럼, 1,000억 달러 규모의 AI 안전 기금 조성 ................................................... 7\\n   - 골드만삭스, 데이터 투명성을 위한 데이터 출처 탐색 공개 ............................................................ 8\\n   - 알림바르 클라우드, 최신 LLM '동이치웰 2.0' 공개 ................................................................... 9\\n   - 삼성전자, 자체 개발 생성 AI '삼성 차우' 공개 ......................................................................... 10\\n   - 구글, 애드스프레드 20억 달러 투자 생성 AI 협력 3화 ................................................................ 11\\n   - IDC, 2027년 AI 소프트웨어에 매출 2,500억 달러 추정 전망 ............................................................ 12\\n   - 빌 게이츠, AI 에이전트를 통한 컴퓨터 사용의 변화를 전망 ................................................................ 13\\n   - 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화 ......................................................................... 14\\n\\n3. 기술/연구\\n   - 영국 과학학술신소부, AI 안전 연구소 설립 발표 .......................................................................... 15\\n   - 구글 탐내시, 방임 AI 모델의 기능과 동작에 대한 분석 체계 발포 ................................................... 16\\n   - 갈렙마르코와의 LLM 학자 지수 평가에서 GPT-4 가장 우수 ........................................................... 17\\n\\n4. 인력/교육\\n   - 영국 옥스퍼드 인터넷 연구소, AI 기술자의 임금이 평균 21% 높아 ................................................ 18\\n\\n## II. 주요 행사\\n   - CES 2024 ..................................................................................................................................................... 19\\n   - AIMLA 2024 ............................................................................................................................................... 19\\n   - AAAI Conference on Artificial Intelligence ............................................................................................ 19\", content_length=2411, page=2), Page(content='I. 인공지능 산업 동향 브리프', content_length=17, page=3), Page(content=\"# 1. 개정/정체  2. 기업/산업  3. 기술/인력  4. 인재/교육\\n\\n## 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표\\n\\n### KEY Contents\\n- 미국 바이든 대통령이 '안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령'에 서명하고 관련법한 행정 조치를 임시\\n- 행정명령은 AI의 안전과 보안 기준 마련 및 개인정보보호 쇼핑평가과 시민권 향상 소비자 보호 노동자 지원 실식난과 경쟁 촉진 소국제협력을 골자로 함\\n\\n### 바이든 대통령, AI 행정명령 통해 안전하고 신뢰할 수 있는 AI 개발과 활용 추진\\n- 미국 바이든 대통령이 2023년 10월 30일 연방정부 차원에서 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행정명령을 발표\\n- 행정명령은 AI의 안전과 보안 기준 마련 미션정보보호 쇼핑평가와 시민권 향상 소비자 보호 노동자 지원 실식난과 경쟁 촉진 소국제협력한 내용을 포함\\n- (AI 안전과 보안 기준) 강력한 AI 시스템을 개발하는 기업에게 안전 테스트 결과와 시스템에 관한 주요 정보는 미국 정부와 공유할 것을 요구하며, AI 시스템의 안전성과 신뢰성 확인을 위한 표준 AI 상용 콘텐츠 표시는 위한 표준과 모범 사례를 활용하도록 함\\n- △10^26 플롭스(FLOPS, Floating Point Operation Per Second) 를 초과하는 컴퓨터 성능 또는 생물학적 서브 데이터를 주로 사용하는 10^3 플롭스를 초과하는 컴퓨터를 사용하는 모델 스탠드 데이터센터에서 1,000Gbit/s 이상의 네트워크로 연결되어 이론적인 수준에서 최대 10^20 플롭스를 처리할 수 있는 컴퓨터 용량을 갖춘 컴퓨터 클래스가 정보보호당함\\n- (행정성 시민권 향상) 방법, 주택, 보건 분야에서 AI의 무책임한 사용으로 인한 차별과 편견 및 기타 문제를 방지하는 조치를 착색\\n- 형사법 시스템에서 AI 사용 모범 사례를 개발하며, 주택 분야 AI 알고리즘 차별을 막기 위한 명확한 지침을 제공하며, 보건경제 부문에서의 AI 사용을 위한 전략을 마련\\n- (소비자 보호와 근로자 지원) 의로 노동에 책임이 있는 AI 사용을 추진하고 맞춤형 개별적인 동 학교 내에서 교육 도구 관련 자원을 개발하며, AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과 모범 사례를 마련\\n- (혁신과 경쟁 촉진) 국가연구자원(National Artificial Intelligence Research Resource, NAIRR)*을 통해 미국 전역의 AI 연구를 촉진하고, 중소기업의 개발과 기술과 인프라를 지원\\n  - *각 차원에서 AI 연구 프로그램을 활용하여 더 많은 연구자에게 인프라 지원하는 프로그램 \\n  - 비자 기초과 인터뷰 지원과 현대화와 간소화로 AI 관련 분야 자원을 갖춘 전문가들이 미국에서 고용하고 활용할 수 있도록 지원\\n\\n### 출처: The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (E.O. 14110), 2023.10.30.\", content_length=1550, page=4), Page(content='# G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의\\n\\n## KEY Contents\\n\\n- G7이 철단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인 행동강령을 마련\\n- 행동관리는 수행주체 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와 이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구\\n\\n## G7, 철단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련\\n\\n- 주요 7개국(G7)*은 2023년 10월 30일 ‘히로시마 AI 프로세스’를 통해 AI 기업 대상의 AI 국제 행동강령(International Code of Conduct for Advanced AI Systems)에 합의\\n- G7은 2023년 5월 일본 히로시마에서 개최된 정상회의에 생성 AI에 관한 국제규범 마련을 정보공유를 위해 ‘히로시마 AI 프로세스’를 출범**\\n  \\n** 기업의 자발적 채택을 위해 마련된 이번 행동강령은 기본모델과 생성을 포함한 철단 AI 시스템의 위험 식별과 완화를 필요로 하는 조치를 포함  \\n* 주요 7개국(G7)은 미국, 일본, 독일, 영국, 프랑스, 이탈리아, 캐나다 포함\\n** 주최 정상회의에는 한국, 호주, 베트남 등이 포함되었지만, AI 국제 행동강령에선 국내 기업 참여에 채택\\n\\n- G7의 행동강령을 통해 아래의 조치를 제시했으며, 빠른 발전하는 기술에 대응할 수 있도록 이해관계자 협력이 필요함에 따라 개정할 예정\\n\\n- 철단 AI 시스템의 개발 과정에서 AI 수행주체 간의 결제 위험을 평가 및 완화하는 조치를 취해하고, 철단 AI 시스템의 출시는 배포 이후 위험과 오류 사고, 요용 등을 고려하여 완화\\n- 철단 AI 시스템의 성과와 한계를 공개하고 적절하나 부족점한 사용 영역을 알리는 방법으로 투명성을 보장하고 책임성을 강화\\n\\n- 산업계, 정부, 시민사회, 학계를 포함해 철단 AI 시스템을 개발하는 조직 정보 공유와 사고 발생 시 신속을 위해 협력하고, 위험 기반 방침식으로 데이터를 개인정보 보호 정책과 위험 완화 조치를 포함하는 AI 거버넌스와 위험 관리 정책을 마련\\n\\n- AI 수행주체 전반에 걸쳐 훈련받고, 사용해보며, 내부적 위험 보완을 포함한 보안 체계 구축\\n\\n- 사용자가 AI 생성 콘텐츠를 식별할 수 있도록 위드모델을 비슷하게 가능한 기법으로 신뢰할 수 있는 콘텐츠 인증과 출처 확인 메커니즘을 개발 구축\\n\\n- 사회적 위험과 안전 문제를 혼합하는 연구효과 및 응답에 우선 투하하고, 기후 위기 대응, 세계 보고서 교육 등 세계적 난제 해결을 위한 철단 AI 시스템을 개발\\n\\n- 국제 기술 표준화 개발 제안과 개인정보와 지식재산권 보호를 위해 데이터 입력과 수준 제정할 보호 장치 구축\\n\\n⏭ 출처: G7, Hiroshima Process International Code of Conduct for Advanced AI Systems, 2023.10.30.', content_length=1450, page=5), Page(content='# 1. 정황/배경 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n\\n## 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언\\n\\n### KEY Contents\\n- 영국 블렛츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전성을 위한 협력 방안을 담은 블렛츨리 선언을 발표\\n- 현장 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 참여하였으며, 영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정\\n\\n### AI 안전성 정상회의의 참가국들, 블렛츨리 선언 등을 통해 AI 안전 보장을 위한 협력에 합의\\n- 2023년 11월 1-2일 영국 블렛츨리 파크에서 열린 AI 안전성 정상회의(AI Safety Summit)에 참가한 28개국 대표들이 AI 위험 관리를 위한 ‘블렛츨리 선언’을 발표\\n- 선언은 AI 안전 보장을 위해 국가, 국제기구, 기업, 시민사회, 학계를 포함한 모든 이해관계자의 협력이 중요하다고 강조했으며, 특히 최첨단 AI 시스템 개발 기업은 안전 평가를 비롯한 적절한 조치를 취하여 AI 시스템의 안전 보장을 책임지고 있음을 지적\\n- 각국은 AI 안전 보장을 위해 첨단 AI 개발자의 책임 강조, 적절한 평가자와 안전 테스트 도구 개발, 공공분모 역할 확대와 과학적 연구개발 등 분야에서 협력하기로 합의\\n\\n### 영국 총리, 정부 주도로 참가 AI 시스템 안전 테스트 계획 발표\\n- 리시 수낵 영국 총리는 AI 안전성 정상회의를 마무리하며 참가 모델에 대한 안전성 시험 계획 수립과 테스트 수행을 주도할 영국 AI 안전 연구소의 출범을 발표\\n- 참가 AI 모델의 안전 테스트는 국가 안보와 안전, 사회적 피해를 포함한 여러 잠재적 유해 기능에 대한 평가를 포함하며, 참석자들은 정부 외부의 안전 테스트에 협의\\n- 각국 정부는 테스트와 기타 안전 연구를 위한 공공분모 역할에 투자하며, 테스트 결과가 다른 국가와 관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 발표를 노력하기로 합의\\n\\n### 참가국들은 튼튼한 안전 기준이 요구되는 벤지오 교수 주도로하는 ‘과학의 현황(State of the Science)’ 보고서 작성에 합의였으며, 보고서를 통해 신AI 위험 가능성과 관련 기존 연구를 포괄적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획\\n\\n> 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1–2 November 2023, 2023.11.01. Gov.uk, World leaders, top AI companies and researchers begin testing of frontier AI Safety Summit concludes, 2023.11.02.', content_length=1402, page=6), Page(content='# 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기관\\n\\n## KEY Contents\\n- 미국 캘리포니아 북부지방법원은 미드저니, 스테이블디퓨전, 디비앙트아트를 대상으로 예술가 3인이 제기한 저작권 침해 소송 기관\\n- 법원은 기관 이유로 고소장에 체시된 상단작 작품이 저작권청에 등록되지 않았으며, 시로 생성된 이미지와 특정 작품 간 유사성을 인정하기 어렵다는 점을 제시\\n\\n## 예술가들의 AI 저작권 침해 소송, 저작권 미등록과 증거결부론으로 기관\\n- 미국 캘리포니아 북부지방법원의 윌리엄 오릭(William Orick) 판사는 2023년 10월 30일 미드저니(Midjourney), 스테이블디퓨전(Stability AI), 디비언트아트(DeviantArt)에 제기된 저작권 침해 소송을 기관\\n- 2023년 1월 예술가 사라 앤더슨(Sarah Anderson), 캘리 맥커넌(Kelly McKernan), 칼라 오르티즈(Karla Ortiz)는 이들 기업의 AI 모델이 예술가의 저작권 침해를 제기\\n- 예술가들은 3개 기업이 이 모델을 활용하기 위해 원작자 동의 없이 작품을 학습 데이터셋에 포함하여 저작권을 침해했다고 주장하며, 법원은 지난 4월 피소 기업들이 제출한 기관 신청을 수용해 소송을 기관\\n\\n- 오릭 판사는 판결문에서 소송을 기각한 핵심 이유로 예술가들의 저작권 미등록을 제시\\n- 판결문은 소송을 제기한 캘리 맥커넌과 칼라 오르티즈가 그러한 저작권에 대한 저작권을 제첨하지 않았다는 점을 지적했으며, 사라 앤더슨은 고소장이 침해된 특정 이미지들 중 16개 작품에 대해선 저작권을 보유\\n\\n- 판결문은 또한 생성 AI 모델 훈련에 사용된 모든 이미지에 저작권이 있거나, 생성 시로 만든 이미지가 저작물을 이용해 훈련되었으므로 저작권의 파손 이미지는 주장은 개연성이 부족하다고 지적\\n\\n- 이는 새로운 이미지를 생성할 때 다양한 예술가의 작품을 참조하므로, 생성된 이미지와 저작권을 가진 특정 작품과의 실질적 유사성을 입증할 수 없다는 저작권 침해를 인정하기 어려움\\n\\n- 오릭 판사는 원고 측에 고소장을 수정하여 저작권이 침해된 특정 이미지를 중심으로 소송 범위를 줄여 소송을 다시 제기할 것을 요청\\n- 단, 사라 앤더슨의 저작권을 보유한 16개 작품을 무도로 북텍스트 스테이블디퓨전에 대한 저작권 침해 소송은 인정하도록 계속 통감됨\\n', content_length=1152, page=7), Page(content=\"```markdown\\n# 1. 정책/법체\\n## 2. 기업/산업\\n## 3. 기술/연구\\n## 4. 인력/교육\\n\\n# 미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 촉진의 AI 의견서 제출\\n\\n## KEY Contents\\n- 미국 FTC는 저작권이 실신한 저작권과 AI 관련 질문공고에 대해 소비자 보호와 경쟁 촉면의 의견을 제시\\n- FTC는 생성 AI로 인한 창작자와 소비자의 피해에 우려를 표시는 한편, 일부 빅테크가 막대한 재원을 활용해 시장 지배력을 더욱 강화할 수 있다는 우려를 제기\\n\\n### FTC, 생성 AI로 인한 소비자와 창작자의 피해 및 빅테크의 시장 지배력 강화 우려\\n- 미국 연방거래위원회(FTC)가 2023년 10월 30일 저작권청(U.S. Copyright Office, USCO)이 지난 9월 발표한 저작권과 AI 관련 질문공고(Notice of Inquiry, NOI)에 대한 의견서를 발표\\n- 저작권과 생성 AI와 관련된 저작권법 정책 이슈를 조사하고 있으며, 폭넓은 의견 수렴을 통해 입법과 규제 조치의 필요성을 검토할 계획\\n- FTC는 생성 AI의 개발과 배포가 소비자, 근로자, 중소기업에 피해를 줄 수 있다는 소비자의 개인정보 침해, 차별적 편견의 작동, 사기 및 범죄와 관련된 위험에 주목\\n- FTC는 저작권에 따른 권리와 책임의 범위를 넘어서는 저작권 문제에 주목하여 생성 AI로 인해 창작자의 경쟁력이 불공정한 피해를 볼 수 있으며, 소비자가 특정 창작자의 작품을 생성 시기가 만들었다고 의하며 소지가 있다고 지적\\n- 저작권법이 저작되는 행위에 불공정 경쟁이 기관행위에 해당될 수 있으며, 창작자의 평과 평, 저작물의 가치 저하나 개인정보 유출로 소비자에 상당한 피해를 초래 가능\\n- FTC는 일부 빅테크가 막대한 재원을 활용해 생성 AI 사용자의 이탈을 막고 저작권에 대한 데이터를 독점, 독점 과점해 시장 지배력을 더욱 강화할 수 있다는 우려를 제기\\n- 이와 관련 FTC는 아마존 AI 비서 '알렉사(Alexa)'와 스마트홈 보안 기기 '링(Ring)'의 소비자의 사적 정보를 알고리듬 훈련에 사용하여 프라이버시 침해 관련을 활용해 AI 관련 법적 행위에 대해 조사하고 있음\\n  * FTC는 2023년 5월 31일 돈을 받지 않고 어린이의 음성을 위약적으로 활용한 '알렉사'와 고객의 지식 영시에 대해 직업에 규제한 전형을 부과 '량이 3,080억 달러와 420억 원의 과징금을 부과\\n- FTC는 발면리 발전하는 생성 AI가 여러 산업과 비즈니스에 변화를 가져올 수 있지만, 현행법상 이에 관한 예외 조항은 없으며, 모든 권한을 활용해 소비자 보호와 개방적인 경쟁 시장을 유지하겠다고 강조\\n\\n## 출처: FTC, In Comment Submitted to U.S. Copyright Office, FTC Raises AI-related Competition and Consumer Protection Issues, Stressing That It Will Use Its Authority to Protect Competition and Consumers in AI Markets, 2023.10.30.\\n```  \", content_length=1542, page=8), Page(content=\"# EU AI 법 3차 협상, 기초모델 규제 관련 견해차로 난항\\n\\n## KEY Contents\\n- 유럽의회, EU 집행위원회, EU 이사회가 진행 중인 AI 법 최종합의에서 프랑스, 이탈리아, 독일의 기초모델에 대한 규제에 반대하며 협상이 난관에 봉착\\n- 프랑스, 이탈리아, 독일 3개국은 기초모델 개발기업에 대한 자율적 행동강령을 도입하고 준수를 의무화하는 방안을 제안\\n\\n### AI 법 3차 협상, 이사회 일부 국가가 기초모델 규제에 반대하며 차질\\n- 유럽의회, EU 집행위원회, EU 이사회가 'AI 법 (AI act)'에 대한 최종합의가 진행 중인 가운데, 일부 국가가 기초모델에 대한 규제에 반대하며 협상이 난관에 봉착\\n- 10월 24일 열린 3차 협상회의에서는 사회에 큰 영향을 미치는 강력한 AI 모델에 더 엄격한 규제를 적용하는 계층적 접근방식에 따라 기초모델 규제에 대한 기본적인 합의에 도달\\n- 그러나 11월 10일 열린 통상전반 회의에서 EU 이사회의 프랑스, 독일, 이탈리아 대표가 기초모델에 대한 모든 유형의 규제에 반대하며 협상이 중단됨\\n- 유럽 정책 네트워크 유레티브(Euractive)에 따르면 프랑스 SL 기업 미스트랄(Mistral)의 로비를 통해 기초모델에 대한 규제 반대를 주도\\n- 독일의 대표적인 AI 기업 알레프 알파(Aleph Alpha) 역시 독일 정부의 압력을 행사하고 있으며, 이들 기업은 EU의 AI 규제에 의해 미국과 중국의 경쟁상대보다 뒤쳐질 것을 우려\\n\\n### 독일, 프랑스, 이탈리아 3개국, 기초모델에 대한 '의무적 자유규제' 제안\\n- 통상직업한 회의가 결렬된 이후 독일, 프랑스, 이탈리아는 2023년 11월 19일 비공식 문서들을 통해 '의무적 자유규제(Mandatory Self-regulation)' 방식의 기초모델 규제를 제안\\n- 3개국은 기초모델 전반에 대한 규제와 기술 중립성이 위험 기반 AI 규제 원칙에 어긋난다며, 주장하는 기초모델 전반에 대한 규제가 아닌, 특정 용도로 사용할 수 있는 시스템에 대한 규제를 요구\\n- 3개국은 자발적인 행동강령을 도입하고 준수를 의무화하는 방안을 제안하며, 기초모델 개발기업에 머신러닝 기술 정보가 모델의 기능과 함께 요구되는 '모델 카드' 작성이 요구된다고 설명\\n- 3개국은 기술과 모델 카드들을 토대로 기초모델 개발기업의 행동강령 준수를 여부를 확인하려는 심사 기법을 제정하지 않고 반향분석과 영향 평가를 시행한 후 제재하는 방안을 제안\\n\\n*출처: Euractiv, EU's AI Act negotiations hit the brakes over foundation models, 2023.11.1. Euractiv, France, Germany, Italy push for 'mandatory self-regulation' for foundation models in EU's AI law, 2023.11.19.*\", content_length=1415, page=9), Page(content='# 미국 프론티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성\\n\\n## KEY Contents\\n- 구글, 앤솔럽, 마이크로소프트, 오픈AI가 참여하는 프론티어 모델 포럼이 자선단체와 함께 AI 안전 연구를 위한 1,000만 달러 규모의 AI 안전 기금을 조성\\n- 프론티어 모델 포럼은 AI 모델의 취약점을 발굴하고 검증하는 레딧 활동을 지원하기 위한 모델 평가 기반 개발에 자금을 증진 지원할 계획\\n\\n## 프론티어 모델 포럼, 자선단체와 함께 AI 안전 연구를 위한 기금 조성\\n- 구글, 앤솔럽, 마이크로소프트, 오픈AI가 출현한 프론티어 모델 포럼이 2023년 10월 25일 AI 안전 연구를 위한 기금을 조성한다고 발표\\n- 참가자들은 맥거번 재단(Patrick J. McGovern Foundation), 데이빗 앤 루시 리팩드 재단(The David and Lucile Packard Foundation) 등의 자선단체와 함께 AI 안전 연구를 위한 기관에 1,000만 달러 이상을 기부\\n- 또한 신기술의 개발자에게 안전 분야에서 전문성을 갖춘 블루밍스 연구소 출신의 크리스 메세롤리스(Chris Meserole)를 포럼의 상무이사로 임명\\n- 최근 AI 기술이 급속히 발전하면서 AI 안전에 관한 연구가 부족한 상황이, 포럼은 이러한 격차를 해소하기 위해 AI 안전 기금 조성\\n- 참가자들은 지난 7월 발빠른 주예 AI 안전 서약에서 외부자에 의한 시스템 취약점 발견과 신고를 촉진하기로 약속했으며, 약속을 이행하기 위해 기금을 활용해 외부 연구자단의 AI 시스템 평가에 자금을 지원할 계획\\n\\n## AI 안전 기금으로 AI 레딧을 위한 모델 평가 기반 개발을 증진 지원할 계획\\n- 프론티어 모델 포럼은 AI 안전 기금을 통해 AI 레딧 활동을 위한 새로운 모델 평가 기반의 개발을 증진 지원할 예정\\n- 포럼에 따르면 AI 레딧에 대한 자금 지원은 모델의 안전성과 보안 기준에 맞게 시스템 위험 대응 방안에 관한 산학연계 정부, 시민사회협력에 도움이 될 전망으로, 포럼은 향후 몇 달 안에 기금 지원을 위한 제안 요청을 발송 계획\\n- 프론티어 모델 포럼은 출범 이후 적게 전반에 걸쳐 AI 레딧 구성에 관한 모델의 공유를 추진하는 한편, 전다시 AI 모델의 취약점이나 잠재적으로 위험한 기능 및 위험 관련 정보를 공유할 수 있는 공개 절차도 개발 중\\n\\n* 출처: Google, Anthropic, Google, Microsoft and OpenAI announce Executive Director of the Frontier Model Forum and over $10 million for a new AI Safety Fund, 2023.10.25.', content_length=1326, page=10), Page(content='# 교하여, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\\n\\n## KEY Contents\\n\\n- 교하여 12개 기관이 광범위한 데이터셋에 대한 감사를 통해 원본 데이터출처, 재라이센스 상태, 작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\\n- 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 구성과 캐도 추적 가능\\n\\n## 데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통한 데이터 투명성 향상\\n\\n- AI 기업 코헤어(Cohere)가 매사추세츠 공과대학(MIT), 하버드 로스쿨, 카네기멜론스 등 12개 기관과 함께 2023년 10월 25일 ‘데이터 출처 탐색기(Data Provenance Explorer)’ 플랫폼을 공개\\n- AI 모델 훈련에 사용되는 데이터셋의 불법적인 출처로 인해 데이터 투명성이 확보되지 않아 다양한 법적, 윤리적 문제가 발생\\n- 이에 연구진은 가장 널리 사용되는 2,000여 개의 미세조정 데이터셋을 감수 추적하며 데이터셋의 원본 데이터에 대한 태그, 재라이센스(Relicensing) 상태, 제작자, 기타 데이터 속성을 지정하고 이러한 정보에 접근할 수 있는 플랫폼을 출시\\n- 대화형 플랫폼 형태의 데이터 출처 탐색기를 통해 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며, 주요 데이터셋의 구성과 데이터 캐도 추적 가능\\n- 연구진은 오픈소스 데이터셋에 대한 광범위한 감사를 통해 데이터 투명성에 영향을 미치는 중요한 요인을 발견\\n  - 저자별(GitHub), 페이퍼미드코드(Papers with Code)와 같은 오픈소스 플랫폼에서 수집한 데이터로 훈련된 오픈소스 LLM에서는 데이터 라이선스의 녹락 비율이 72-83%에 달함\\n  - 또한 클라우드소스 플랫폼이 활용한 라이선스는 데이터셋 원저작자의 의도보다 더 광범위한 사용을 허용한 경우가 성황수\\n- 데이터 선택에 대한 분석 결과, 부정확하거나 모호한 라이선스 문서화 등 데이터 출처 일종과 관련된 관행 전반에서 구조적 문제가 드러남\\n- 연구자는 데이터 출처 탐색기만으로 해결이 어려운 법적 이슈도 조사하더며 일반적인 법적 프레임워크의 필요성을 제기\\n- 일례로 데이터를 수집하는 지역, 모델 훈련 지역, 모델 배포 지역마다 규제가 다르면 어떤 법률을 적용해야 하는지 실무자들 간의 의견을 수렴하고, 서로 다른 라이선스를 적용하는 개발 데이터셋을 하나로 통합하여 사용하는 경우에도 각각의 라이선스 조건에서 어려움이 발생', content_length=1217, page=11), Page(content='# 1. 정보/발표 2. 기업/산업 3. 기술/마감 4. 인재/교육\\n\\n## 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개\\n\\n### KEY Contents\\n- 알리바바 클라우드는 복잡한 지칭 이해, 광고문구 작성, 추천, 맥기 등에 성능이 향상된 최신 LLM ‘통이치엔원 2.0’을 공개\\n- 알리바바 클라우드는 산업별로 특화된 생성 AI 모델을 공개하는 한편, 모델 개발과 애플리케이션 구축 절차를 간소화하는 올인원 AI 모델 구축 플랫폼도 출시\\n\\n### 알리바바의 통이치엔원 2.0, 주요 벤치마크 테스트에서 여타 LLM 능가\\n- 중국의 알리바바 클라우드가 2023년 10월 31일 열린 연례 기술 컨퍼런스에서 최신 LLM ‘통이치엔원(Tongyi Qianwen) 2.0’을 공개\\n- 알리바바 클라우드는 통이치엔원 2.0을 2023년 4월 출시된 1.0 버전보다 복잡한 지칭 이해, 광고문구 작성, 추천, 맥기 등에서 성능이 향상되었다고 설명\\n- 통이치엔원 2.0은 이에 따라 테스팅(MMLU), 추적(GSM8K), 질문 답변(ARC-C)과 같은 벤치마크 테스트에서 라마(Llama-2-70B)와 GPT-3.5를 비슷한 주요 AI 모델 능가\\n- 통이치엔원 2.0은 알리바바 클라우드의 플랫폼을 통해 앱을 제공하며 개발자는 API를 통해 사용 가능\\n\\n### 알리바바 클라우드는 여러 산업 영역에서 생성 AI를 활용해 사업 성과를 개선할 수 있도록 지원하는 산업별 모델도 출시\\n- 산업 영역은 고객지원, 법률 상담, 의료, 금융, 문서관리, 오디오와 동영상 관리, 코드 개발, 캐릭터 제작을 포함\\n\\n### 알리바바 클라우드는 급증하는 생성 AI 수요에 대응해 모델 개발과 애플리케이션 구축 절차를 간소화하는 올인원 AI 모델 구축 플랫폼 ‘GenAI(GenAI)’도 공개\\n- 이 플랫폼은 데이터 관리, 모델 배포 및 평가, 지속한 엔지니어링을 통한 통합 도구 모음을 제공하여 다양한 기업들이 맞춤형 AI 모델을 한층 쉽게 개발할 수 있도록 지원\\n- 생성 AI 개발에 필요한 컴퓨팅 데이터 처리 요구사항을 지원하기 위해 AI 플랫폼(PAI), 데이터베이스 솔루션, 컨테이너 서비스와 같은 클라우드 신제품도 발표\\n\\n### 알리바바 클라우드는 AI 개발을 촉진하기 위해 올해 말까지 720억 개 매개변수를 가진 통이치엔원 모델을 오픈소스화할 계획도 공개\\n', content_length=1152, page=12), Page(content='# 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\n\\n## KEY Contents\\n- 삼성전자 가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 AI 모델 ‘삼성 가우스’를 공개\\n- 삼성전자는 삼성 가우스를 다양한 체형에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 삼성 가우스는 외부로 사용자 유출의 위험이 없다는 장점을 보유\\n\\n## 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\n- 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 ‘삼성 가우스’를 최초 공개\\n- 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본딴 삼성 가우스는 다양한 상황에 최적화된 크기의 모델 선택이 가능\\n- 삼성 가우스는 라이선스화한 개인정보를 침해하지 않는 안전한 데이터 통하여 학습되었으며, 온디바이스에서 작동하도록 설계되도 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n- 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술을 소개했으며, 생성 AI 모델은 다양한 제형에 단계적으로 탑재할 계획\\n- 삼성 가우스는 스크립트를 생성하는 언어모델 스코드를 생성하는 코드 모델 스크립지를 생성하는 이미 스모델의 3개 모델 구성\\n- 언어 모델은 클라우드와 온디바이스를 대상으로 모델로 구성되며, 이메일 작성, 문서 요약, 번역 업무 처리를 지원\\n- 코드 모델 기반의 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 신규 소프트웨어 개발에 최적화\\n- 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원할 때 보다 빠를 수 있도록 지원하며 저해상도 이미지의 고해상도 전환도 지원\\n\\n## 참고\\n- 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n- 삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\n- TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.', content_length=1066, page=13), Page(content='# 구글, 앤스프릭에 20억 달러 투자로 생성 AI 협력 강화\\n\\n## KEY Contents\\n\\n- 구글이 앤스프릭에 최대 20억 달러 투자해 합의하고 5억 달러를 우선 투자했으며, 앤스프릭은 구글 클라우드 서비스 사용 계약도 체결\\n- 3대 클라우드 사업자인 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인 앤스프릭 및 오픈AI와 협력을 확대하는 추세\\n\\n## 구글, 앤스프릭에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\\n\\n- 구글은 2023년 10월 27일 앤스프릭에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억 달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\\n- 구글은 2023년 2월 앤스프릭에 이미 5억 5,000만 달러를 투자한 바 있으며, 아마존은 지난 9월 앤스프릭에 최대 40억 달러의 투자 계획을 공개\\n- 한편, 2023년 11월 블룸버그 보도에 따르면 앤스프릭은 구글의 클라우드 서버 사용을 위해 4년간 30억 달러 규모의 계약을 체결\\n- 오픈AI 창립자 고흐훌 옆자인 대리오 아모데이(Dario Amodei)와 다니엘라 아모데이(Daniela Amodei) 남매가 2021년 설립한 앤스프릭은 챗GPT의 대망 클릭(Claude) LLM 개발\\n\\n- 아마존과 구글의 앤스프릭 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈AI와 협력 확대\\n- 마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 대해 2023년 1월 추가로 100억 달러를 투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure) 클라우드 플랫폼을 사용해 AI 모델을 훈련\\n\\n## 구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\\n\\n- 구글은 수익성이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를 통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자 지속\\n- 구글은 앤스프릭 외에도 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어 기업 허깅페이스(Hugging Face)에도 투자\\n- 구글은 첫 GPT의 기반 기술과 직접 경쟁할 수 있는 차세대 LLM ‘제미니(Gemini)’를 포함한 자체 시스템 개발에도 수십억 달러를 투자했으며, 2024년 제미니를 출시할 계획\\n\\n출처: The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27. Bloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09.', content_length=1326, page=14), Page(content='# IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망\\n\\n## KEY Contents\\n- IDC의 예측에 의하면 AI 소프트웨어 시장은 2027년 2,510억 달러로 성장하며, 생성 AI 플랫폼과 애플리케이션은 2027년까지 283억 달러의 매출을 창출할 전망\\n- 2023년 기준 AI 소프트웨어 매출의 3분기 1위를 차지하는 최대 시장인 AI 애플리케이션은 2027년까지 21.1%의 연평균 성장률을 기록할 전망\\n\\n## 기업들의 AI 투자 증가에 힘입어 AI 소프트웨어 시장 급성장 예상\\n- 시장조사기관 IDC는 AI 소프트웨어 시장이 2022년 640억 달러에서 2027년 2,510억 달러로 연평균 성장률 31.4%를 기록하며 급성장할 것으로 예상\\n- AI 소프트웨어 시장은 AI 플랫폼, AI 애플리케이션, 신 시스템 인프라 소프트웨어(SSI), AI 애플리케이션 개발 배포(AI AD&D) 소프트웨어를 포함\\n- 협업, 콘텐츠 관리, 전사적 자원관리(ERM), 공급망 관리, 생산 및 운영, 엔지니어링, 고객관계관리(CRM)를 포함하는 AI 애플리케이션은 신 AI 소프트웨어의 최대 시장으로 2023년 전체 매출의 약 3분기 1위를 차지하며 2027년까지 21.1%의 연평균 성장률을 기록할 전망\\n- AI 비서를 포함한 AI 모델과 애플리케이션의 개발은 AI 플랫폼의 두 번째로 큰 시장을 구성하며, 2027년까지 35.8%의 연평균 성장률이 예상됨\\n- 분석, 비즈니스 인텔리전스, 데이터 관리와 통합을 포함하는 신 SSI는 기존 소프트웨어의 시스템화 통합되어 방대한 데이터를 활용한 AI 최적화 운영 최적화를 지원하며, 현재 매출 규모는 비교적 적지만 5년간 연평균 성장률은 32.6%로 시장 전체를 웃돈 전망\\n- 애플리케이션 개발, 소프트웨어의 품질 수명주기 관리 소프트웨어, 애플리케이션 플랫폼을 포함하는 AI ADB는 향후 5년간 카테고리 중 가장 높은 38.7%의 연평균 성장률이 예상됨\\n\\n## IDC에 따르면 경제적 불확실성과 시장 역학의 변화에도 AI 자동화 기술에 대한 기업들의 투자 의지는 확고하며, 기업들은 AI 도입이 사업 경쟁력에 필수적이라고 인식\\n- IDC 설문조사에 따르면 향후 12개월 동안 응답자의 3분의 1은 기업의 특정 사용 사례와 응용 영역에서 외부 AI 소프트웨어의 구매를 고려하며 외부 AI 소프트웨어와 내부 자원의 결합을 고려\\n\\n## 한편, AI 소프트웨어에 시장이 포함되지 않는 사례 플랫폼과 애플리케이션은 2027년까지 283억 달러의 매출을 창출할 전망\\n', content_length=1245, page=15), Page(content='', content_length=0, page=16), Page(content='', content_length=0, page=17), Page(content='', content_length=0, page=18), Page(content='', content_length=0, page=19), Page(content='', content_length=0, page=20), Page(content='', content_length=0, page=21), Page(content='', content_length=0, page=22), Page(content='', content_length=0, page=23)])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:44:30.681975Z",
     "start_time": "2025-07-06T22:44:25.074666Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install \"unstructured[md]\" nltk",
   "id": "5d6236e17a192c8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\r\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting unstructured[md]\r\n",
      "  Downloading unstructured-0.18.3-py3-none-any.whl.metadata (24 kB)\r\n",
      "Collecting chardet (from unstructured[md])\r\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Collecting filetype (from unstructured[md])\r\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting python-magic (from unstructured[md])\r\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Collecting lxml (from unstructured[md])\r\n",
      "  Downloading lxml-6.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from unstructured[md]) (2.32.4)\r\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.11/site-packages (from unstructured[md]) (4.13.4)\r\n",
      "Collecting emoji (from unstructured[md])\r\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\r\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.11/site-packages (from unstructured[md]) (0.6.7)\r\n",
      "Collecting python-iso639 (from unstructured[md])\r\n",
      "  Using cached python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting langdetect (from unstructured[md])\r\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from unstructured[md]) (2.3.1)\r\n",
      "Collecting rapidfuzz (from unstructured[md])\r\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting backoff (from unstructured[md])\r\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.11/site-packages (from unstructured[md]) (4.14.0)\r\n",
      "Collecting unstructured-client (from unstructured[md])\r\n",
      "  Downloading unstructured_client-0.38.1-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting wrapt (from unstructured[md])\r\n",
      "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from unstructured[md]) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from unstructured[md]) (7.0.0)\r\n",
      "Collecting python-oxmsg (from unstructured[md])\r\n",
      "  Using cached python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Collecting html5lib (from unstructured[md])\r\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting markdown (from unstructured[md])\r\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk) (8.2.1)\r\n",
      "Collecting joblib (from nltk)\r\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4->unstructured[md]) (2.7)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->unstructured[md]) (3.26.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->unstructured[md]) (0.9.0)\r\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured[md]) (24.2)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[md]) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.9 in ./.venv/lib/python3.11/site-packages (from html5lib->unstructured[md]) (1.17.0)\r\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.11/site-packages (from html5lib->unstructured[md]) (0.5.1)\r\n",
      "Collecting olefile (from python-oxmsg->unstructured[md])\r\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->unstructured[md]) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->unstructured[md]) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->unstructured[md]) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->unstructured[md]) (2025.6.15)\r\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured[md]) (24.1.0)\r\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured[md])\r\n",
      "  Downloading cryptography-45.0.5-cp311-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured[md]) (0.28.1)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured[md]) (1.6.0)\r\n",
      "Requirement already satisfied: pydantic>=2.11.2 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured[md]) (2.11.7)\r\n",
      "Requirement already satisfied: pypdf>=4.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured[md]) (5.7.0)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured[md]) (1.0.0)\r\n",
      "Requirement already satisfied: cffi>=1.14 in ./.venv/lib/python3.11/site-packages (from cryptography>=3.1->unstructured-client->unstructured[md]) (1.17.1)\r\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured[md]) (2.22)\r\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[md]) (4.9.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[md]) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[md]) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[md]) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[md]) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[md]) (0.4.1)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[md]) (1.3.1)\r\n",
      "Downloading unstructured-0.18.3-py3-none-any.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m35.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\r\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\r\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\r\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\r\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\r\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\r\n",
      "Downloading lxml-6.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.2/5.2 MB\u001B[0m \u001B[31m41.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading markdown-3.8.2-py3-none-any.whl (106 kB)\r\n",
      "Using cached python_iso639-2025.2.18-py3-none-any.whl (167 kB)\r\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\r\n",
      "Using cached python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\r\n",
      "Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\r\n",
      "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m38.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading unstructured_client-0.38.1-py3-none-any.whl (212 kB)\r\n",
      "Downloading cryptography-45.0.5-cp311-abi3-manylinux_2_28_x86_64.whl (4.5 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m38.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\r\n",
      "Installing collected packages: filetype, wrapt, rapidfuzz, python-magic, python-iso639, olefile, markdown, lxml, langdetect, joblib, html5lib, emoji, chardet, backoff, python-oxmsg, nltk, cryptography, unstructured-client, unstructured\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m19/19\u001B[0m [unstructured]m━━\u001B[0m \u001B[32m18/19\u001B[0m [unstructured]client]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed backoff-2.2.1 chardet-5.2.0 cryptography-45.0.5 emoji-2.14.1 filetype-1.2.0 html5lib-1.1 joblib-1.5.1 langdetect-1.0.9 lxml-6.0.0 markdown-3.8.2 nltk-3.9.1 olefile-0.47 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 unstructured-0.18.3 unstructured-client-0.38.1 wrapt-1.17.2\r\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:49:19.248117Z",
     "start_time": "2025-07-06T22:49:19.234981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 100,\n",
    "    separators=['\\n\\n', '\\n']\n",
    ")"
   ],
   "id": "1c5e85f988c1d67b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:49:49.476295Z",
     "start_time": "2025-07-06T22:49:48.857667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "markdown_path = \"./documents/brief_2023년12월호_f.md\"\n",
    "loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "document_list = loader.load_and_split(text_splitter)"
   ],
   "id": "48b60e5bec813119",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:51:16.541549Z",
     "start_time": "2025-07-06T22:51:16.533844Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(document_list))",
   "id": "a128365b482b716a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 더 나은 파싱을 위해 마크다운 > TEXT > LOAD > SPLIT 처리",
   "id": "c1eb7606827e6b91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:53:38.407817Z",
     "start_time": "2025-07-06T22:53:37.418656Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -q markdown html2text beautifulsoup4",
   "id": "bf16d54264e2af23",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:55:32.391565Z",
     "start_time": "2025-07-06T22:55:32.360765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "text_path = './documents/brief_2023년12월호_f.txt'\n",
    "\n",
    "# 마크다운 파일을 읽어옵니다\n",
    "with open(markdown_path, 'r', encoding='utf-8') as md_file:\n",
    "    md_content = md_file.read()\n",
    "\n",
    "# 마크다운 콘텐츠를 HTML로 변환합니다\n",
    "html_content = markdown.markdown(md_content)\n",
    "\n",
    "# HTML 콘텐츠를 파싱하여 텍스트만 추출합니다\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text_content = soup.get_text()\n",
    "\n",
    "# 추출한 텍스트를 텍스트 파일로 저장합니다\n",
    "with open(text_path, 'w', encoding='utf-8') as txt_file:\n",
    "    txt_file.write(text_content)\n",
    "\n",
    "print(\"Markdown converted to plain text successfully!\")"
   ],
   "id": "bce99eb61b503de2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown converted to plain text successfully!\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:56:04.574428Z",
     "start_time": "2025-07-06T22:56:04.569156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(text_path)\n",
    "document_list = loader.load_and_split(text_splitter)"
   ],
   "id": "589c835755d94d7f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T22:56:16.943326Z",
     "start_time": "2025-07-06T22:56:16.937855Z"
    }
   },
   "cell_type": "code",
   "source": "document_list[10]",
   "id": "dc1c610d602ed5b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './documents/brief_2023년12월호_f.txt'}, page_content='알리바바의 통이치엔원 2.0, 주요 벤치마크 테스트에서 여타 LLM 능가\\n\\n중국의 알리바바 클라우드가 2023년 10월 31일 열린 연례 기술 컨퍼런스에서 최신 LLM ‘통이치엔원(Tongyi Qianwen) 2.0’을 공개\\n알리바바 클라우드는 통이치엔원 2.0을 2023년 4월 출시된 1.0 버전보다 복잡한 지칭 이해, 광고문구 작성, 추천, 맥기 등에서 성능이 향상되었다고 설명\\n통이치엔원 2.0은 이에 따라 테스팅(MMLU), 추적(GSM8K), 질문 답변(ARC-C)과 같은 벤치마크 테스트에서 라마(Llama-2-70B)와 GPT-3.5를 비슷한 주요 AI 모델 능가\\n통이치엔원 2.0은 알리바바 클라우드의 플랫폼을 통해 앱을 제공하며 개발자는 API를 통해 사용 가능\\n\\n알리바바 클라우드는 여러 산업 영역에서 생성 AI를 활용해 사업 성과를 개선할 수 있도록 지원하는 산업별 모델도 출시\\n\\n산업 영역은 고객지원, 법률 상담, 의료, 금융, 문서관리, 오디오와 동영상 관리, 코드 개발, 캐릭터 제작을 포함\\n\\n알리바바 클라우드는 급증하는 생성 AI 수요에 대응해 모델 개발과 애플리케이션 구축 절차를 간소화하는 올인원 AI 모델 구축 플랫폼 ‘GenAI(GenAI)’도 공개\\n\\n이 플랫폼은 데이터 관리, 모델 배포 및 평가, 지속한 엔지니어링을 통한 통합 도구 모음을 제공하여 다양한 기업들이 맞춤형 AI 모델을 한층 쉽게 개발할 수 있도록 지원\\n생성 AI 개발에 필요한 컴퓨팅 데이터 처리 요구사항을 지원하기 위해 AI 플랫폼(PAI), 데이터베이스 솔루션, 컨테이너 서비스와 같은 클라우드 신제품도 발표\\n\\n알리바바 클라우드는 AI 개발을 촉진하기 위해 올해 말까지 720억 개 매개변수를 가진 통이치엔원 모델을 오픈소스화할 계획도 공개\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nKEY Contents\\n\\n삼성전자 가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 AI 모델 ‘삼성 가우스’를 공개\\n삼성전자는 삼성 가우스를 다양한 체형에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 삼성 가우스는 외부로 사용자 유출의 위험이 없다는 장점을 보유\\n\\n언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:05:38.928280Z",
     "start_time": "2025-07-06T23:05:37.845672Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -q langchain-chroma pysqlite3-binary",
   "id": "bc43ebd079683db1",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:05:43.235023Z",
     "start_time": "2025-07-06T23:05:43.228835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SQLite3 버전 문제 해결: Chroma는 SQLite3 3.35.0 이상이 필요하지만 시스템에는 낮은 버전이 설치되어 있음\n",
    "# pysqlite3-binary를 사용하여 더 높은 버전의 SQLite3을 제공\n",
    "import sys\n",
    "import pysqlite3\n",
    "# 기존 sqlite3 모듈을 pysqlite3으로 대체\n",
    "sys.modules['sqlite3'] = pysqlite3\n",
    "print(f\"Using SQLite version: {pysqlite3.sqlite_version}\")"
   ],
   "id": "1ba64a873d67d7a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SQLite version: 3.46.1\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:05:50.555005Z",
     "start_time": "2025-07-06T23:05:50.529748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')"
   ],
   "id": "537931b0437d4bda",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:11:13.291727Z",
     "start_time": "2025-07-06T23:11:11.433887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import Chroma after setting up sqlite3\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=document_list,\n",
    "    embedding=embeddings,\n",
    "    collection_name = 'brief',\n",
    "    persist_directory = './brief'\n",
    ")"
   ],
   "id": "72504f91968b9f6c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: module 'chromadb' has no attribute 'get_settings'\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: module 'chromadb' has no attribute 'get_settings'\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:11:17.691100Z",
     "start_time": "2025-07-06T23:11:17.688297Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = vector_store.as_retriever(search_kwargs={'k': 3})",
   "id": "4ce3da5e52379a7e",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:11:19.512566Z",
     "start_time": "2025-07-06T23:11:19.506852Z"
    }
   },
   "cell_type": "code",
   "source": "query = '구글의 LLM 관련 투자 규모는?'",
   "id": "9532f44c9fb79f0",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:11:56.560515Z",
     "start_time": "2025-07-06T23:11:55.591955Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.invoke(query)",
   "id": "237a4c112f277cfe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: module 'chromadb' has no attribute 'get_settings'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='09964d55-41c0-4798-acc7-e9a7a47b59d6', metadata={'source': './documents/brief_2023년12월호_f.txt'}, page_content='아마존과 구글의 앤스프릭 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈AI와 협력 확대\\n\\n마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 대해 2023년 1월 추가로 100억 달러를 투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure) 클라우드 플랫폼을 사용해 AI 모델을 훈련\\n\\n구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\\n\\n구글은 수익성이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를 통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자 지속\\n구글은 앤스프릭 외에도 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어 기업 허깅페이스(Hugging Face)에도 투자\\n구글은 첫 GPT의 기반 기술과 직접 경쟁할 수 있는 차세대 LLM ‘제미니(Gemini)’를 포함한 자체 시스템 개발에도 수십억 달러를 투자했으며, 2024년 제미니를 출시할 계획\\n\\n출처: The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27. Bloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09.\\nIDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망\\nKEY Contents\\n\\nIDC의 예측에 의하면 AI 소프트웨어 시장은 2027년 2,510억 달러로 성장하며, 생성 AI 플랫폼과 애플리케이션은 2027년까지 283억 달러의 매출을 창출할 전망\\n2023년 기준 AI 소프트웨어 매출의 3분기 1위를 차지하는 최대 시장인 AI 애플리케이션은 2027년까지 21.1%의 연평균 성장률을 기록할 전망\\n\\n기업들의 AI 투자 증가에 힘입어 AI 소프트웨어 시장 급성장 예상'),\n",
       " Document(id='0e9c3b70-c04b-46bb-9cf5-99cf1c3dcd51', metadata={'source': './documents/brief_2023년12월호_f.txt'}, page_content='아마존과 구글의 앤스프릭 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈AI와 협력 확대\\n\\n마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 대해 2023년 1월 추가로 100억 달러를 투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure) 클라우드 플랫폼을 사용해 AI 모델을 훈련\\n\\n구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\\n\\n구글은 수익성이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를 통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자 지속\\n구글은 앤스프릭 외에도 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어 기업 허깅페이스(Hugging Face)에도 투자\\n구글은 첫 GPT의 기반 기술과 직접 경쟁할 수 있는 차세대 LLM ‘제미니(Gemini)’를 포함한 자체 시스템 개발에도 수십억 달러를 투자했으며, 2024년 제미니를 출시할 계획\\n\\n출처: The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27. Bloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09.\\nIDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망\\nKEY Contents\\n\\nIDC의 예측에 의하면 AI 소프트웨어 시장은 2027년 2,510억 달러로 성장하며, 생성 AI 플랫폼과 애플리케이션은 2027년까지 283억 달러의 매출을 창출할 전망\\n2023년 기준 AI 소프트웨어 매출의 3분기 1위를 차지하는 최대 시장인 AI 애플리케이션은 2027년까지 21.1%의 연평균 성장률을 기록할 전망\\n\\n기업들의 AI 투자 증가에 힘입어 AI 소프트웨어 시장 급성장 예상'),\n",
       " Document(id='6eb706be-de49-46e7-8c1b-b0c297b4587f', metadata={'source': './documents/brief_2023년12월호_f.txt'}, page_content='데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통한 데이터 투명성 향상\\n\\nAI 기업 코헤어(Cohere)가 매사추세츠 공과대학(MIT), 하버드 로스쿨, 카네기멜론스 등 12개 기관과 함께 2023년 10월 25일 ‘데이터 출처 탐색기(Data Provenance Explorer)’ 플랫폼을 공개\\nAI 모델 훈련에 사용되는 데이터셋의 불법적인 출처로 인해 데이터 투명성이 확보되지 않아 다양한 법적, 윤리적 문제가 발생\\n이에 연구진은 가장 널리 사용되는 2,000여 개의 미세조정 데이터셋을 감수 추적하며 데이터셋의 원본 데이터에 대한 태그, 재라이센스(Relicensing) 상태, 제작자, 기타 데이터 속성을 지정하고 이러한 정보에 접근할 수 있는 플랫폼을 출시\\n대화형 플랫폼 형태의 데이터 출처 탐색기를 통해 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며, 주요 데이터셋의 구성과 데이터 캐도 추적 가능\\n연구진은 오픈소스 데이터셋에 대한 광범위한 감사를 통해 데이터 투명성에 영향을 미치는 중요한 요인을 발견\\n저자별(GitHub), 페이퍼미드코드(Papers with Code)와 같은 오픈소스 플랫폼에서 수집한 데이터로 훈련된 오픈소스 LLM에서는 데이터 라이선스의 녹락 비율이 72-83%에 달함\\n또한 클라우드소스 플랫폼이 활용한 라이선스는 데이터셋 원저작자의 의도보다 더 광범위한 사용을 허용한 경우가 성황수\\n데이터 선택에 대한 분석 결과, 부정확하거나 모호한 라이선스 문서화 등 데이터 출처 일종과 관련된 관행 전반에서 구조적 문제가 드러남\\n연구자는 데이터 출처 탐색기만으로 해결이 어려운 법적 이슈도 조사하더며 일반적인 법적 프레임워크의 필요성을 제기\\n일례로 데이터를 수집하는 지역, 모델 훈련 지역, 모델 배포 지역마다 규제가 다르면 어떤 법률을 적용해야 하는지 실무자들 간의 의견을 수렴하고, 서로 다른 라이선스를 적용하는 개발 데이터셋을 하나로 통합하여 사용하는 경우에도 각각의 라이선스 조건에서 어려움이 발생\\n\\n1. 정보/발표 2. 기업/산업 3. 기술/마감 4. 인재/교육\\n알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개\\nKEY Contents\\n\\n알리바바 클라우드는 복잡한 지칭 이해, 광고문구 작성, 추천, 맥기 등에 성능이 향상된 최신 LLM ‘통이치엔원 2.0’을 공개\\n알리바바 클라우드는 산업별로 특화된 생성 AI 모델을 공개하는 한편, 모델 개발과 애플리케이션 구축 절차를 간소화하는 올인원 AI 모델 구축 플랫폼도 출시\\n\\n알리바바의 통이치엔원 2.0, 주요 벤치마크 테스트에서 여타 LLM 능가')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
